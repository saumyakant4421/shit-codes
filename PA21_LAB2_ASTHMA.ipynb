{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3457,
     "status": "ok",
     "timestamp": 1738565557964,
     "user": {
      "displayName": "Mrudula Wani",
      "userId": "06942653902981193844"
     },
     "user_tz": -330
    },
    "id": "aDC9TOislJZM",
    "outputId": "85d3aa0e-b8b9-437f-f42c-96214fcf669c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/codespace/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/codespace/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/codespace/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After Stopword Removal: Hi Saumya speaking .\n",
      "After Stemming: hi saumya speak .\n",
      "After Lemmatization: Hi Saumya speaking .\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "\n",
    "# Download necessary data\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Initialize tools\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stemmer = PorterStemmer()\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Function: Remove stopwords\n",
    "def remove_stopwords(text):\n",
    "    words = word_tokenize(text)\n",
    "    return [word for word in words if word.lower() not in stop_words]\n",
    "\n",
    "# Function: Apply stemming\n",
    "def apply_stemming(words):\n",
    "    return [stemmer.stem(word) for word in words]\n",
    "\n",
    "# Function: Apply lemmatization\n",
    "def apply_lemmatization(words):\n",
    "    return [lemmatizer.lemmatize(word) for word in words]\n",
    "\n",
    "# Main execution\n",
    "text_input = input(\"Enter a sentence: \")\n",
    "\n",
    "# Step 1: Stopword Removal\n",
    "filtered_words = remove_stopwords(text_input)\n",
    "print(\"\\nAfter Stopword Removal:\", \" \".join(filtered_words))\n",
    "\n",
    "# Step 2: Stemming\n",
    "stemmed_words = apply_stemming(filtered_words)\n",
    "print(\"After Stemming:\", \" \".join(stemmed_words))\n",
    "\n",
    "# Step 3: Lemmatization\n",
    "lemmatized_words = apply_lemmatization(filtered_words)\n",
    "print(\"After Lemmatization:\", \" \".join(lemmatized_words))\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "1dDzJu2Szp1tE5167ndusBulppuVfg_gX",
     "timestamp": 1738566031626
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
