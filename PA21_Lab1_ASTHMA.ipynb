{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FX0wdhhwSEwW"
   },
   "outputs": [],
   "source": [
    "# Lab-1: Apply various text-preprocessing techniques on a sample text\n",
    "#Experiment No. 1\n",
    "#Parth Kumbhar 1032222259\n",
    "#PA 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2HtOLrw0SUZr"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.12.10' requires the ipykernel package.\n",
      "\u001b[1;31m<a href='command:jupyter.createPythonEnvAndSelectController'>Create a Python Environment</a> with the required packages.\n",
      "\u001b[1;31mOr install 'ipykernel' using the command: 'c:/Users/Administrator/AppData/Local/Microsoft/WindowsApps/python3.12.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# LOWERCASE\n",
    "def lower_case_text(text):\n",
    "  return text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KarYlfoXSa4k"
   },
   "outputs": [],
   "source": [
    "# REMOVING PUNCTUATIONS\n",
    "def remove_punctuations(text):\n",
    "  punctuations= \".,'(){}[];:<>?/!@#%&*+=_-~`$^%|\\\"\"\n",
    "\n",
    "  no_punct=\"\"\n",
    "  for char in text:\n",
    "    if char not in punctuations:\n",
    "      no_punct+=char\n",
    "\n",
    "  return no_punct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 405,
     "status": "ok",
     "timestamp": 1737959885912,
     "user": {
      "displayName": "Pragya Mittal",
      "userId": "13563567174854871363"
     },
     "user_tz": -330
    },
    "id": "rwwJxZKuSZY7",
    "outputId": "709ee019-450f-451d-826b-2f8405a8e400"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# STOPWORD REMOVAL\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "stop_words= stopwords.words('english')\n",
    "print(stop_words)\n",
    "\n",
    "def remove_stopwords(text):\n",
    "  filtered_tokens=[]\n",
    "  for token in text:\n",
    "    if token not in stop_words:\n",
    "      filtered_tokens.append(token)\n",
    "\n",
    "  return filtered_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 548,
     "status": "ok",
     "timestamp": 1737959634403,
     "user": {
      "displayName": "Pragya Mittal",
      "userId": "13563567174854871363"
     },
     "user_tz": -330
    },
    "id": "H9OlUzcnVB_2",
    "outputId": "93ddffea-f113-4b29-d05a-6838d62b7b19"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# TOKENIZATION\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "def tokenize(text):\n",
    "  tokens= nltk.word_tokenize(text)\n",
    "  # tokens= nltk.word_tokenize(\"hello! how are you?\")\n",
    "  return tokens\n",
    "\n",
    "  # OR\n",
    "  # split= remove_punctuations(text).split(' ')\n",
    "  # return split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BUd1VDPpbw2X"
   },
   "outputs": [],
   "source": [
    "# CREATING PIPELINE\n",
    "\n",
    "def pre_process_pipeline(text):\n",
    "  text= lower_case_text(text)\n",
    "  text= remove_punctuations(text)\n",
    "  text= tokenize(text)\n",
    "  text= remove_stopwords(text)\n",
    "  return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1737960039302,
     "user": {
      "displayName": "Pragya Mittal",
      "userId": "13563567174854871363"
     },
     "user_tz": -330
    },
    "id": "i63ytyo_dx92",
    "outputId": "6168a7da-102d-4b59-9914-cde2b3a14ae0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hello', 'said', 'went', 'alphonso', 'mango', 'favorite', 'fruit', 'whole', 'world']\n"
     ]
    }
   ],
   "source": [
    "sample_text= \"Hello!! he said, and went..: (alphonso) mango IS My favorite FruiT in whole World!\"\n",
    "tokens= pre_process_pipeline(sample_text)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 530,
     "status": "ok",
     "timestamp": 1738561696075,
     "user": {
      "displayName": "Mrudula Wani",
      "userId": "06942653902981193844"
     },
     "user_tz": -330
    },
    "id": "zCo4muTdSv0R",
    "outputId": "3cc0cfc3-2699-4787-abe9-58434cb03b2b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Customer_ID    City\n",
      "0          101  Mumbai\n",
      "2          103  Mumbai\n"
     ]
    }
   ],
   "source": [
    "#text filtration\n",
    "import pandas as pd\n",
    "\n",
    "# Creating DataFrame with customer ID and city\n",
    "data = {'Customer_ID': [101, 102, 103, 104, 105],\n",
    "        'City': ['Mumbai', 'Pune', 'Mumbai', 'Delhi', 'Bangalore']}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Defining filtration criteria (Customers from Mumbai)\n",
    "filtered_df = df[df['City'] == 'Mumbai']\n",
    "\n",
    "# Printing the output\n",
    "print(filtered_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9824,
     "status": "ok",
     "timestamp": 1738563264593,
     "user": {
      "displayName": "Mrudula Wani",
      "userId": "06942653902981193844"
     },
     "user_tz": -330
    },
    "id": "f2Ll9MuDWtiQ",
    "outputId": "e6061195-f502-4047-94a6-9a7bce4ff8fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the script: Python is a powerful programming language used for data science, web development, and automation. It provides various libraries like pandas and NumPy to simplify complex tasks. Many developers prefer Python due to its readability and versatility.\n",
      "Enter the word to check: web\n",
      "Valid\n"
     ]
    }
   ],
   "source": [
    "#script validation\n",
    "\n",
    "def validate_script(script, word):\n",
    "    if word in script:\n",
    "        return \"Valid\"\n",
    "    else:\n",
    "        return \"Not Valid\"\n",
    "\n",
    "# Taking input from the user\n",
    "script_input = input(\"Enter the script: \")\n",
    "word_input = input(\"Enter the word to check: \")\n",
    "\n",
    "\n",
    "result = validate_script(script_input, word_input)\n",
    "print(result)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "1uJ0vabTwzkho1TheJIYgJMGtjx8iRluc",
     "timestamp": 1738565954070
    },
    {
     "file_id": "1fkVgw0ragwPDDcleOGh6wzHkH8TQ55OC",
     "timestamp": 1737961963110
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
